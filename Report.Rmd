---
title: "Capestone Project"
author: "James Strayer"
date: "02/01/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---



# Introduction
I was given data from a Restaurant that sales some of their product in retail to find a model to predict the sales, The data start from 2015

## Data import and cleaning
```{r echo=FALSE}
if(!require(tidyverse)){
  install.packages("tidyverse")
  library(tidyverse)
}
#Importing data
DailySales<-read_csv("https://raw.githubusercontent.com/jjamesSt/CapestoneProject/master/Data/DailySales.csv")
glimpse(DailySales)
```

In our data set we have 10 variables for 1715 observations corresponding to the number of days the restaurant was open since the 29-03-2015.We can remove the fiscal year .The Month variable is in a format not pratical for analysis (Month, YY) we want to have just the Full moth written without the year. So for simplicity and because we have the full date in the Date column, we are going to remove the month column as it is and create a new one based on the date column, we will do the same for the weekdays column. Furthermore we don't need the day number in our analysis so we will remove it too:
```{r }
#Remove unncessary column for the analysis
DataForAnalysis<-DailySales%>%select(-Weekday,-Month,-Day,-`annee fiscale`)
#Add a column for weekday and month
DataForAnalysis<-DataForAnalysis%>%mutate(Weekday=weekdays(Date),Month=months(Date))
```
If we look again at the data we see that we have a Sales column, representing the Total Sales for the day and then each column after it, is the total sales for each day for each component of the restaurant possible sales revenu, so Retail, Take-out, Bar and Restaurant. We can see that there is NAs in all of those data
```{r }
#looking for NAs in the sales data
sum(is.na(DataForAnalysis$Sales))
sum(is.na(DataForAnalysis$Bar_Sales))
sum(is.na(DataForAnalysis$Retail))
sum(is.na(DataForAnalysis$TakeOutSales))
sum(is.na(DataForAnalysis$Sales_Restaurant))
```
we will change those NAs to 0, considering a $0 CAD sales for that day and variable
```{r }
#Chaning NAs to 0 in the sales data
DataForAnalysis[is.na(DataForAnalysis$Sales),]$Sales<-0
DataForAnalysis[is.na(DataForAnalysis$Bar_Sales),]$Bar_Sales<-0
DataForAnalysis[is.na(DataForAnalysis$Retail),]$Retail<-0
DataForAnalysis[is.na(DataForAnalysis$TakeOutSales),]$TakeOutSales<-0
DataForAnalysis[is.na(DataForAnalysis$Sales_Restaurant),]$Sales_Restaurant<-0
```

# Data exploration
```{r}
#look at the structure of the data
glimpse(DataForAnalysis)
```
We want to have full years to have the same thing amount of days in the year to predict 2019 weeks. So we filter for 2016 and more

```{r,echo=FALSE}
#filter for 2016,2017,2018 and 2019
DataForAnalysis<-DataForAnalysis%>%filter(Year>=2016)
```
```{r}
#Summary statistics for the variable
summary(DataForAnalysis)
```


## Sales Variable
```{r,echo=FALSE}
#Distribution of Sales by Year
DataForAnalysis%>%group_by(Year)%>%ggplot(aes(x=Date,y=Sales,group=Year))+geom_boxplot()+ggtitle("Sales distribution by Year")
```
We see In the box plot above that 2019 was similar to 2018 in term of sales but with 2 outliers
```{r, echo=FALSE}
#Distribution of Sales by weekday for each year
DataForAnalysis%>%group_by(Weekday)%>%ggplot(aes(x=Weekday,y=Sales))+geom_boxplot()+facet_wrap(DataForAnalysis$Year)+ggtitle("Sales distribution by Day of the Week for each year")
```

In the box plot above we see that in 2019 they were very few Sales on Mondays and that the biggest, through the years, were Thursday, Friday and Saturday.
##Preparing Data for Modeling
I will be considering this data as a time series and such I will use a library made to handle them
```{r,echo=FALSE}
if(!require(timetk)){
  install.packages("timetk")
}
library(timetk)
#package for ARIMA model
if(!require(forecast)){
  install.packages("forecast")
}
library(forecast)
#Broom-style tidiers for forecast package
if(!require(sweep)){
  install.packages("sweep")
}
library(sweep) 
```
We then transform the data to train and test data. We use 2016 to 2018 to predict 2019 sales data:
```{r,echo=FALSE}
#creation of train_set and test_set
train_set<-DataForAnalysis%>%filter(Year <2019)
test_set<-DataForAnalysis%>%filter(Year==2019)
```

# Modeling Data
## ARIMA Model
We are going to test to 2 models to predict sales at a given week knowing the previous weeks. We will wan to try to predict the first week of 2019. We going to compare Linear Regression and ARIMA (Auto Regressive Integrated Moving Average) model (you can have a brief summary of ARIMA model here:https://machinelearningmastery.com/gentle-introduction-box-jenkins-method-time-series-forecasting/)

We first transform our train data to a time series and plot the sales over the years
```{r,fig.align='center', echo=FALSE}
if(!require(forecast)){
  install.packages("forecast")
}
library(forecast)
#Broom-style tidiers for forecast package
if(!require(sweep)){
  install.packages("sweep")
}
library(sweep)
#Create time series with just Days and total sales for the model trainings
##zoo is a package that allows to index tibble on Date column which is essential for time series
if(!require(zoo)){
  install.packages("zoo")
}
library(zoo)
#Transform the train set and the test set to a zoo format so it can be easilier transform to a time series thanks to the index on the Date
set.seed(412,sample.kind = "Rounding")
zoo_train<-train_set%>%select(-Weekday,-Month,-Year,-Retail,-TakeOutSales,-Bar_Sales,-Sales_Restaurant)%>% read.zoo(.,format="%F")
ts_train<-ts(zoo_train,start=2016,end=2019,frequency = 365)
#Show the time serie
plot(ts_train)
labs(title = "Sales Times Series by year")
```
We see that over the 3 years the data looks sationary, so we'll use a 7 days lag with a moving average window of 45 days to we define our model as:
```{r}
#Build ARIMA model
set.seed(412,sample.kind = "Rounding")
fit_arima<-Arima(ts_train,c(7,0,45))

summary(fit_arima)
#see the acutal value with the prediction
sw_augment(fit_arima,timetk_idx = TRUE)
```
By looking at the residual we see that most of it is between -1000 and 1000 with quite few outliers, the model seems good considering the quantity of data:
```{r,fig.align='center',echo=FALSE}
sw_augment(fit_arima, timetk_idx = TRUE) %>% 
  ggplot(aes(x = index, y = .resid)) +
    geom_point(colour = 'blue', size = 2) + 
    geom_line() +
    geom_hline(yintercept = 0, color = "red") + 
    labs(title = "Residual diagnostic") +
    theme_classic()
```
Once we have our model we can forecast the next 365 days of our data,so 2019. We see that the ARIMA(7,0,45) model does not predict the high spikes of sales but still distinguish 7 different pattern, that correspond to the distribution of days of the week. 

```{r,fig.align='center', echo=FALSE}
predict_arima<-forecast(fit_arima,h=365)
#Get the forecast value in a table
fcast_tbl <- sw_sweep(predict_arima,timetk_idx =TRUE)
fcast_tbl
#select test set data corresponding to the predicted data
actual_tbl <- test_set
#Visualize with actual value
fcast_tbl %>% 
   ggplot(aes(x = index, y = value, color = key)) +
   geom_point() +
  #Actual data
   geom_line(data = actual_tbl, aes(x = Date, y = Sales), color = 'red',alpha=0.1)+
   #geom_point(data = actual_tbl, aes(x = Date, y = Sales), color = 'red') +
   labs(title = "Sales Forecast: ARIMA", x = "", y = "Canadian Dollard",
          subtitle = "sw_sweep tidies the auto.arima() forecast output") +
   scale_x_date(date_breaks = "1 year", date_labels = "%F")
#Calculate the error
error_arima<- fcast_tbl %>% filter(key == 'forecast') %>% 
                            left_join(actual_tbl, by=c("index"="Date")) %>% 
                            mutate(date = index,actual = Sales, pred = value) %>% 
                            select(date,actual,pred) %>% 
                            mutate(error = actual - pred,
                                   error_pct = error/actual)
error_arima
```

## Linear Regression
To ease the comparison of the models we are going to first transform our full data set to an augmented timeserie, which give us specification on the day, month and years of the Date column. We remove the same variable as the ARIMA model to create our train and test set data for the linear model 
```{r,echo=FALSE}
#transform Data to time series for linear regression
DataLr<-DataForAnalysis%>%tk_augment_timeseries_signature()
#Define train and test set
trainLr_set<-DataLr%>%filter(Date<'2019-01-01')
trainLr_set<-trainLr_set%>% select(-Retail,-TakeOutSales,-Bar_Sales,-Sales_Restaurant)
testLr_set<-DataLr%>%filter(Date>='2019-01-01')
testLr_set<-testLr_set%>% select(-Retail,-TakeOutSales,-Bar_Sales,-Sales_Restaurant)
str(trainLr_set)
str(testLr_set)
```
We define our linear model such as all the variable defined in our train set is used to predict the Sales variable:
```{r}
set.seed(42,sample.kind = "Rounding")
fit_Lr<-lm(Sales~.,data=select(trainLr_set,-Date))
summary(fit_Lr)
```
We see that all the variable created by the augmented ts was used to define the model to predict our sales. Now that the model is trained, we can predict the test Data with our model
```{r,fig.align='center'}
predict_lr<-predict(fit_Lr,newdata=select(testLr_set,-Date))
error_lr<-testLr_set%>%select(Date,actual=Sales)%>%
  mutate(pred=predict_lr,
         error=actual-predict_lr,
         error_pct=error/actual)
error_lr
dataToPlot<-testLr_set%>%add_column(pred=predict(fit_Lr,testLr_set)%>%tibble::enframe(name = NULL) %>% pull(value))
dataToPlot %>%
 ggplot(aes(x = Date, y = pred)) +
 geom_line() +
geom_point()+
geom_line(data = testLr_set,aes(x=Date,y=Sales),color="red",alpha=0.5)+
 scale_x_date(date_breaks = "1 year", date_labels = "%F") +
 scale_color_manual(
  values = c(
   "weekly_sales" = "blue",
   "lm_pred" = "#fdc7d7"
  )
 ) +
 theme_classic() +
 labs(title = "model fit",
  subtitle = "test data: 2019",
  x = "Date",
  y = "daily sales (in CAD)"
  )
```
On the plot above we see in red The actual value of sales and in black the prediction made by the linear regression model.

# Discussion
We see that the linear regression has a better accuracy than the ARIMA model for predicting the sales for 2019. But The ARIMA model is able to differentiate the trends between the weekdays. One Interesting way we could improve the ARIMA would be to try to find the best ARIMA model for each day in a week for all the years in the data set and combine them to have a better approximation of the sales for any given day and would allows us to compare the sales to the same day last year. 
We see that both models failed to predict the high spikes of sales corresponding to the middle of the year, April through October, when the sidewalk sitting area is open, which give to the restaurant more sitting places, so potentially more sales. Furthermore it might be interesint to include weather data to analyse the effect of rainy days (or snowy days) on the sales of the Restaurant. 
